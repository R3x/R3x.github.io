[{"content":"LLVM Tips/Tricks This is a collection of tips/tricks that I have learned while working with LLVM. I will keep updating this page as I learn more.\n(Last updated: 31st October 2022)\nDebugging LLVM (opt) passes with VSCode Refer to this blog post: Debugging LLVM (opt) passes with VSCode to ease the process of debugging LLVM passes using VSCode\u0026rsquo;s amazing debugging capabilities.\nGenerating the CFG for a function Using IDA Pro for reverse engineering binaries, has made me a huge fan of CFGs, for analyzing control flows for low level applications. Generating CFGs have been pretty helpful for me to analyze control flows especially when I use opt passes to transform the IR.\nopt itself provides a way to generate CFGs for a given llvm-ir file. You can use the following command to generate the CFG for a function:\nopt -disable-verify -dot-cfg --cfg-func-name=\u0026lt;function-name\u0026gt; --cfg-dot-filename-prefix=\u0026lt;path + prefix\u0026gt; \u0026lt;target bitcode file\u0026gt; The bitcode file can be either a .bc file or a .ll file. The CFG will be generated in the .dot format. It\u0026rsquo;s usually in a file named \u0026lt;prefix\u0026gt;_\u0026lt;function-name\u0026gt;.dot.\nIf you only want the basic blocks, but not the IR instructions inside the basic blocks, you can replace the -dot-cfg flag with -dot-cfg-only. If you want the CFG of all the functions, you can just remove the --cfg-func-name flag. Each function will be generated in a separate .dot file.\nNote: The disable-verify flag is used to disable the verification pass, which is not required for generating the CFG. This helps us to generate CFGs for invalid IRs as well, which is useful when we are trying to debug transform opt passes.\nTo view the dot file generated by llvm, you can use the joaompinto.vscode-graphviz extension for VSCode. It will render the dot file in a nice graph that you can zoom in/out and pan around.\nYou need to press Ctrl + Shift + v to open the preview window. You can also use the command palette to open the preview window.\nNote: The joaompinto.vscode-graphviz extension works much better than converting the dot file into a png and then viewing it. This is because the function is too large and the png file is too large to be rendered properly. The extension renders the graph in real time, so you can zoom in/out and pan around the graph. It also some nice features like exporting the graph as a png, svg, etc. If you prefer to do that - without going through the hassle of using the dot command\nLLVM How-Tos Creating and Inserting call to a variable argument function in LLVM IR (using a opt pass) Troubleshooting LLVM issues Instructions get mis-recognized This is an issue you might face if you are working with multiple versions of LLVM. You might compiling your code with one version of LLVM, but the LLVM libraries you are linking against are from a different version. This can cause the instructions to be mis-recognized. This is because the LLVM libraries are compiled with a different version of LLVM, and the instructions are not recognized properly.\nThis is because the LLVM instructions have an ID, and the ID is used to determine the instruction type. The IDs sometimes vary between LLVM versions which cause the instructions to be mis-recognized.\nThe best solution is to not do system-wide installation of LLVM, instead build LLVM from source and use the source directory as the LLVM_DIR when building your project. This will ensure that the LLVM libraries are built with the same version of LLVM that you are using to compile your code. Then use the binaries from the build directory to run your code.\n","permalink":"https://R3x.github.io/posts/llvm_ir_tips/","summary":"LLVM Tips/Tricks This is a collection of tips/tricks that I have learned while working with LLVM. I will keep updating this page as I learn more.\n(Last updated: 31st October 2022)\nDebugging LLVM (opt) passes with VSCode Refer to this blog post: Debugging LLVM (opt) passes with VSCode to ease the process of debugging LLVM passes using VSCode\u0026rsquo;s amazing debugging capabilities.\nGenerating the CFG for a function Using IDA Pro for reverse engineering binaries, has made me a huge fan of CFGs, for analyzing control flows for low level applications.","title":"LLVM Tips/Tricks"},{"content":"Advanced GDB Debugging In this post, I would like to point out some tips/tricks to make debugging easier with GDB. I will be focusing on Linux x86_64 binaries, but most of the things should work on other architectures as well. I will try to cover both\nI am gonna assume basic familiarity with GDB, such as setting breakpoints/stepping through code, etc. If you are not familiar with GDB, I would recommend reading/watching some basic tutorial for GDB.\nUsing the .gdbinit file Gdb uses a file called the .gdbinit file which is used to store all the settings needed when you start gdb. This can be configured on both a systemwide basis and also on a projectwide basis. The root .gdbinit is usually found in the /home directory, and the project specific .gdbinit is usually found in the root of the project directory.\nHowever to load a project specific .gdbinit file when you start gdb, you need to pass the following command to gdb:\ngdb -x \u0026lt;path to .gdbinit file\u0026gt; GDB Advanced Commands GDB has a lot of commands, I plan to try and cover the commands that helped me the most while debugging applications. A good starting tip - is that whenever you are stuck or can\u0026rsquo;t remember the command that you were looking for, try using the apropos command. This is basically a regex search through the commands list and you can usually find the command you were looking for. To get more information about a command, use the help command.\nWatchpoints Watchpoints are used to stop exectuing the program when a certain memory location is read/written. This is useful when you want to know when a certain variable is accessed. But you don\u0026rsquo;t want to set a breakpoint on every single line where the variable may be accessed.\n(gdb) watch __afl_prev_loc Note: watchpoints can be called on any memory address, but you need to cast the address to help determine how many bytes need to be watched. For example, if you want to watch a 4 byte integer, you need to cast the address to (int *)\n(gdb) watch *(int *)0x7fffffffe3e0 You need to use the * to dereference the address else gdb will try to watch the constant address itself.\nwatch - watchpoint for write access rwatch - watchpoint for read access awatch - watchpoint for read/write access Conditional Breakpoints and Watchpoints Conditional breakpoints are a amazing feature of GDB, which allows you to set a breakpoint only if a certain condition is met. This is very useful when you are debugging a basic block that\u0026rsquo;s called multiple times, and you want to stop only when a certain condition is met.\nFor ex, if I want to stop at the call to __afl_maybe_log only if the the value of rcx is 0xdaef, I can use the following command:\n(gdb) break __afl_maybe_log if $rcx == 0xdaef If symbols are available, you can also have checks on condition on the values of variables. For ex, if I want to stop at the call to __afl_maybe_log only if the the value of __afl_prev_loc is 0xdaef, I can use the following command:\n(gdb) break __afl_maybe_log if __afl_prev_loc == 0xdaef Note: Sometimes if the type of the variable is not known you might have to cast it to the correct type, also useful if you are checking the value of a memory address for ex:\n(gdb) break __afl_maybe_log if (unsigned long)__afl_prev_loc == 0xdaef (gdb) break __afl_maybe_log if *(int *)($rbp - 0x10) == 0xdaef (gdb) break __afl_maybe_log if *(int *)0x7fffffffe0a0 == 0xdaef if the breakpoint is already set, you can add a condition to it using the condition command:\n(gdb) condition 1 $rcx == 0xdaef and you can remove the condition using the command :\n(gdb) condition 1 which resets the condition of the breakpoint.\nYou can also choose to ignore the breakpoint a certain number of times by using the ignore command:\n(gdb) ignore 1 5 which will not stop at the breakpoint for the next 5 times, and then start stopping at the breakpoint again.\nCatchpoints Another useful feature, especially when debugging multithreaded C++ applications is the catch command. It allows you to break the execution when a certain event occurs.\nFor ex, if I want to break when a thread is created, I can use the following command:\n(gdb) catch thread create Some common uses are :\ncatch syscall : Break when a syscall is made catch syscall \u0026lt;number/name\u0026gt; : Break when a specific syscall is made catch throw \u0026lt;regex\u0026gt; : Break when a specific exception is thrown (C++) catch catch \u0026lt;regex\u0026gt; : Break when a specific exception is caught (C++) catch signal \u0026lt;number/name\u0026gt; : Break when a specific signal is sent catch load/unload \u0026lt;regex\u0026gt; : Break when a library is loaded/unloaded Custom commands TODO: Briefly explain how to write custom commands\nGDB Python Scripting GDB has a python scripting interface, which I have found to be useful exclusively for CTFs. I will try to quickly go over it, so that people can try it out for themselves.\nRunning a python script with gdb is as simple as running the following command:\ngdb \u0026lt;target/executable\u0026gt; -x \u0026lt;path/to/script.py\u0026gt; if you want to run a python script on a running gdb instance, you can use the source command:\n(gdb) source \u0026lt;path/to/script.py\u0026gt; Defining custom commands in GDB GDB allows you to define custom commands, in python. This is very useful to run a bunch of commands together and add some custom logic to it.\nimport gdb class TestCommand(gdb.Command): def __init__(self): super(TestCommand, self).__init__(\u0026#34;test\u0026#34;, gdb.COMMAND_USER) def invoke(self, arg, from_tty): print(\u0026#34;Test command invoked\u0026#34;) counter = 0 try: total_count = int(arg.split(\u0026#34; \u0026#34;)[0]) skip_count = int(arg.split(\u0026#34; \u0026#34;)[1]) except: print(\u0026#34;Invalid arguments passed\u0026#34;) return print(f\u0026#34;Total count: {total_count}\u0026#34;) print(f\u0026#34;Skip count: {skip_count}\u0026#34;) while counter \u0026lt; total_count: if counter % skip_count == 0: # Skip every skip count iteration gdb.execute(\u0026#34;continue\u0026#34;) continue gdb.execute(\u0026#34;info registers\u0026#34;) counter += 1 gdb.execute(\u0026#34;continue\u0026#34;) TestCommand() The above script defines a custom command called test which takes 2 arguments - total_count and skip_count. The command will print the register values for every iteration, except for every skip_count iteration.\nDefining custom pretty printers Say you have a struct defined as follows:\nstruct Node { int value; struct Node *next; }; While debugging, the program you wish to print the structure of the linked list. You can define a custom pretty printer to do that.\nTODO CTF challenge solving I have used GDB python scripting to solve a few CTF challenges. It\u0026rsquo;s a quick way to get some information from the binary, if you need to extract some runtime information.\nFor ex, here I am extracting characters which are generated during runtime, so that I can use them to reverse the encryption algorithm.\nTODO GDB Plugins There are a lot of extensions available for GDB, which can make your life easier.\nGEF GEF is a GDB extension which adds a lot of useful features to GDB. It\u0026rsquo;s a must have for CTFs. I will try to do another blog post on features specific to GEF that can be really helpful for CTFs.\nDecomp2dbg This is a plugin which allows you to connect GDB to a decompiler. It\u0026rsquo;s shows you the decompiled code in GDB, and allows you to set breakpoints in the decompiled code. It\u0026rsquo;s extremely useful when you are debugging a binary without source code, and allows you to keep in sync with the decompiled code for faster debugging or reverse engineering.\n","permalink":"https://R3x.github.io/posts/gdb_advanced/","summary":"Advanced GDB Debugging In this post, I would like to point out some tips/tricks to make debugging easier with GDB. I will be focusing on Linux x86_64 binaries, but most of the things should work on other architectures as well. I will try to cover both\nI am gonna assume basic familiarity with GDB, such as setting breakpoints/stepping through code, etc. If you are not familiar with GDB, I would recommend reading/watching some basic tutorial for GDB.","title":"Advanced GDB Debugging"},{"content":"Debugging LLVM (opt) passes with VSCode In this blog, I plan to look at how to debug LLVM passes (specifically opt passes) with VSCode. I have been working with opt passes in VSCode for a while, and realized that people have a really hard time debugging them. I have had labmates switch to CLion for writting LLVM passes. So, here\u0026rsquo;s a guide on setting up VSCode for debugging llvm-opt passes.\nSetting up cmake-tools for VSCode Most of the LLVM projects are built using CMake. Let\u0026rsquo;s make the assumption that you are using cmake to build your project.\nFirst, we need to install the cmake-tools extension for VSCode. The extension - ms-vscode.cmake-tools - is a must-have for writing CMake projects in VSCode. It provides a lot of features, including building, debugging, and testing CMake Projects.\nNow you need to create a folder for vscode settings. So from your Project\u0026rsquo;s root directory, run the following command:\nmkdir .vscode cd .vscode code settings.json Now you should have settings.json open, this is the file to add workspace specific configs for the extensions. I will post some of the options that I commonly use, but you can find the full list of options here\n{ // Automatically configure CMake when opening a project workspace (saves you from having to run the CMake: Configure command) \u0026#34;cmake.configureOnOpen\u0026#34;: true, // If your CMakelists.txt is not in the root directory, you can specify the source directory here \u0026#34;cmake.sourceDirectory\u0026#34;: \u0026#34;${workspaceFolder}/passes/\u0026#34;, // If your build directory is not in the root directory, you can specify the build directory here \u0026#34;cmake.buildDirectory\u0026#34;: \u0026#34;${workspaceFolder}/passes/build\u0026#34;, \u0026#34;cmake.clearOutputBeforeBuild\u0026#34;: true, // the -j option for make (typically the number of cores on your machine) \u0026#34;cmake.parallelJobs\u0026#34;: 15, } Now, you can open the project in VSCode and it should automatically configure the project. You can check the output of the cmake-tools extension in the Output tab on VScode.\nSelecting a build target VSCode will automatically configure the project, but it won\u0026rsquo;t build it. You can build the project by running CMake: Build from the command palette.\nNOTE : You can also set a default build target by running CMake: Select a Kit from the command palette. This will open a list of build targets. Select the one you want to build by default.\nOn the bottom left corner of VSCode, you should see the build target. You can click on it to change the build target. If you have multiple passes for example, you can configure it to build all of them or just one of them. By default, it will build all the targets.\nDebugging from CMake Tools NOTE: This step won\u0026rsquo;t work if you are debugging opt-passes, but it might work for people trying to debug standalone executables - such as the clang compiler.\nNormally, VSCode requires a launch.json to debug stuff, it\u0026rsquo;s the file that tells VSCode how to launch the debugger. But, the cmake-tools extension provides a way to debug without setting this up. It doesn\u0026rsquo;t work for all cases, and you can\u0026rsquo;t configure the debugger as much as you can with a launch.json, but it\u0026rsquo;s a good start.\nTry running CMake: Debug from the command palette. If it doesn\u0026rsquo;t work, keep reading to see how to set up a launch.json.\nSetting up a launch.json If you are trying to debug opt passes, you will need to set up a launch.json. The launch.json is a file that tells VSCode how to launch the debugger. You can find the full list of options here.\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Debug (GDB) : MyPass\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, // Since we are debugging an opt pass, we need to specify the path to the opt executable \u0026#34;program\u0026#34;: \u0026#34;/usr/local/bin/opt\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;-f\u0026#34;, // Load the pass library, this is our target \u0026#34;-load\u0026#34;, \u0026#34;${workspaceFolder}/passes/build/MyPass/libMyPass.so\u0026#34;, // Arguments to the pass \u0026#34;-alloca-to-malloc\u0026#34;, // The input bitcode file \u0026#34;\u0026lt;\u0026#34;, \u0026#34;test.bc\u0026#34;, // The output bitcode file \u0026#34;\u0026gt;\u0026#34;, \u0026#34;test2.bc\u0026#34; ], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}/passes\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ], } ] } Now, you can run Debug: Start Debugging from the command palette to start debugging or use F5. You can also set breakpoints in the code and it should work.\nGetting arguments from prompt Sometimes you would want to keep changing parts of the input to the pass. For example, you might want to change the input bitcode file. You can do this by using the args option in the launch.json. But, this is not very convenient. You can do this by defining a input prompt for the file.\nMake the following changes to the launch.json :\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Debug (GDB) : MyPass\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;/usr/local/bin/opt\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;-f\u0026#34;, \u0026#34;-load\u0026#34;, \u0026#34;${workspaceFolder}/passes/build/MyPass/libMyPass.so\u0026#34;, \u0026#34;-alloca-to-malloc\u0026#34;, \u0026#34;\u0026lt;\u0026#34;, \u0026#34;${input:inputBitcode}\u0026#34;, \u0026#34;\u0026gt;\u0026#34;, \u0026#34;test2.bc\u0026#34; ], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}/passes\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ], } ], \u0026#34;inputs\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;inputBitcode\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;promptString\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Input bitcode file\u0026#34;, \u0026#34;default\u0026#34;: \u0026#34;${workspaceFolder}/passes/test.bc\u0026#34; } ] } Now, when you run Debug: Start Debugging from the command palette, you will be prompted to enter the input bitcode file. You can also change the default value in the launch.json to change the default value.\nThe same technique can be used to get flags and other command line arguments for the passes.\nYou can also use the pickString option to select from a list of options. For example, you can use this to select the pass to debug.\n{ \u0026#34;id\u0026#34;: \u0026#34;passToDebug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;pickString\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Pass to debug\u0026#34;, \u0026#34;options\u0026#34;: [ \u0026#34;MyPass\u0026#34;, \u0026#34;MyOtherPass\u0026#34; ] } This means that you can replace your args with the following to select the pass to debug:\n\u0026#34;-load\u0026#34;, \u0026#34;${workspaceFolder}/passes/build/${input:passToDebug}/${input:passToDebug}.so\u0026#34;, Conclusion Well, that\u0026rsquo;s it. I hope this helps you debug your LLVM passes. If you have any questions, feel free to reach out to me. I will try to answer them as soon as I can.\n","permalink":"https://R3x.github.io/posts/llvm_debug/","summary":"Debugging LLVM (opt) passes with VSCode In this blog, I plan to look at how to debug LLVM passes (specifically opt passes) with VSCode. I have been working with opt passes in VSCode for a while, and realized that people have a really hard time debugging them. I have had labmates switch to CLion for writting LLVM passes. So, here\u0026rsquo;s a guide on setting up VSCode for debugging llvm-opt passes.","title":"Debugging LLVM (opt) passes with VSCode"},{"content":"Digging into ELFs (Part 1) In this blog, I plan to look at the ELF file format, specifically the ELF headers, sections and segments. This is gonna be a part of a series that I hope to complete part-by-part this month.\nI am planning to use the LIEF python module to help me look at ELFs and understand what\u0026rsquo;s happening.\nOverview ELF file contains a header and data. The data is divided into segments, each segment can contian a number of sections.\nThe ELF Header Each ELF file, contains a header - which is a collection of information about the ELF file. The following script can be used to view the header of an ELF file.\nimport lief binary = lief.parse(\u0026#34;a.out\u0026#34;) print(binary.header) This gives an output, which looks somewhat like this (I have added comments to make it understandable): Also to mention things that are not shown\nMagic: 7f 45 4c 46 // ELF Magic Number Class: CLASS64 // ELF Class (32 or 64) Endianness: LSB // ELF Endianness (LSB or MSB) Version: CURRENT // The only options are CURRENT and NONE OS/ABI: SYSTEMV // To determine the OS and ABI ABI Version: 0 // To distinguish between different ABI versions (Find incompitability) // IMP : There is typically a padding here of 0s and then a size variable, which is the size of all the fields above File type: DYNAMIC // This field shows whether the file is Executable, Relocatable, Shared or a Core dump file Machine type: x86_64 // This is the Architecture of the file // The above fields are printed in the order they are in the ELF file (modified the LIEF output) Object file version: CURRENT // Another version thing, with the same two options as above Entry Point: 0x4192 // This is a **virtual address**, where the program should start executing Program header offset: 0x64 // Offset to the program header (This is from the start of the file, so it\u0026#39;s at 64(0x40 bytes)) Section header offset: 13968 // Offset to the section header (This is from the start of the file as well) Processor Flag: 0 // Processor flags, currenltly unused Header size: 64 // Size of the ELF header (Note that this is same as the Program header offset, they are adjacent) Size of program header: 56 // Size of each program header entry Number of program header: 13 // Number of program header entries Size of section header: 64 // Size of each section header entry Number of section headers: 31 // Number of section header entries Section Name Table idx: 30 // Shows the index of the section name table (Normally one of the last sections) The above table explains most of the fields in the ELF header.\nThe most important fields are the offsets to the program and section headers. Since these will be used to determine the sections that will be loaded into the address space.\nThe LIEF module provides all the fields as class properties, which can be used to modify the header. The below python script does just that and creates a new ELF file.\n# Modify the ELF header binary.header.entrypoint = 0xdeadbeef binary.header.machine_type = lief.ELF.ARCH.AVR # Write the modified ELF file binary.write(\u0026#34;modifued.elf) The Program Header Each Program Header describes a segment or other information the system needs to prepare the program for execution.\nAs mentioned above, the header contains the offsets to the program header array. Each program header entry is a collection of mutliple values which is used to determine how the segment is leaded into the address space.\nLet\u0026rsquo;s take a look at the first segment using the LIEF module. This should be the segment which contains the ELF program header array.\nphdr_seg = binary.segments[0] print(f\u0026#34;offset = {phdr_seg.file_offset}\u0026#34;) print(f\u0026#34;size = {phdr_seg.physical_size}\u0026#34;) This should give you the following output:\noffset = 64 size = 728 If you look at the offset you will discover that it\u0026rsquo;s exactly the same as the size of the ELF header. And the size is exactly same as the product of the number of program header entries and the size of each program header entry (Mentioned in the header above).\nEach segment header consists of the following fields:\nType : Determines what kind of segment it is, there are few possible types (refer to the Appendix below) Flags : Determines whether the segment is read, write, execute, etc. Offset : The offset from the start of the file to the segment. Virtual/Physical Address : Usually the same, determines the virtual address of the segment. alignment : alignment of the segments in the file. if it\u0026rsquo;s 0/1 then it means there is no alignement. If it\u0026rsquo;s 2^n then it means the segment is aligned to 2^n bytes. NOTE : If a segment is loadable, then it should have consecutive virtual addresses with the previous and the next segments.\nAdditionally, to view the program headers using objdump, you can use the following command:\nobjdump -l a.out The Section Headers A File also will contain a section header table, which will contain all the information about the sections inside the file. It is also an array of structures, with each structure representing a section.\nThe following fields are present in each section header:\nName : Name of the section Type : Each section has a type, which helps determine how to handle it Flags : Determines things such as whether data is writable, whether it contains executable instructions etc. Address : The virtual address of where the section should be present if it\u0026rsquo;s loaded into memory offset : The offset from the start of the file to the section print(binary.sections[1]) which returns the following output (formatted and comments added to make it readable):\n.interp (Name) PROGBITS (Type : Here it means it was a section which holds information) 318 ((792 in decimal) Virtual Address : Note that the address is in hexadecimal) 1c ((28 in decimal) size of the section in bytes) 318 ((792 in decimal) Offset from the start of the file) 3.94076 (Entropy : This is not in the binary, but calculated by LIEF ) ALLOC (Flags : Means the section is in memory) INTERP LOAD (Segment Str : Type of Segments which holds this section, LIEF also prints this information) If you notice the offset, it\u0026rsquo;s the same as the offset + the size of the program header, which is 792 bytes. This means it\u0026rsquo;s adjacent to the program header table segment.\nThe segement string is calculated by LIEF in the following way:\nsegments_str = \u0026#34; - \u0026#34;.join([str(s.type).split(\u0026#34;.\u0026#34;)[-1] for s in section.segments]) Appendix ELF Segment Types (Copied from the man page)\nPT_LOAD The array element specifies a loadable segment, described by p_filesz and p_memsz. The bytes from the file are mapped to the beginning of the memory segment. If the segment\u0026rsquo;s memory size p_memsz is larger than the file size p_filesz, the \u0026ldquo;extra\u0026rdquo; bytes are defined to hold the value 0 and to follow the segment\u0026rsquo;s initialized area. The file size may not be larger than the memory size. Loadable segment entries in the program header table appear in ascending order, sorted on the p_vaddr member. PT_DYNAMIC The array element specifies dynamic linking information. PT_INTERP The array element specifies the location and size of a null-terminated pathname to invoke as an interpreter. This segment type is meaningful only for executable files (though it may occur for shared objects). However it may not occur more than once in a file. If it is present, it must precede any loadable segment entry. PT_NOTE The array element specifies the location of notes (ElfN_Nhdr). PT_SHLIB This segment type is reserved but has unspecified semantics. Programs that contain an array element of this type do not conform to the ABI. PT_PHDR The array element, if present, specifies the location and size of the program header table itself, both in the file and in the memory image of the program. This segment type may not occur more than once in a file. Moreover, it may occur only if the program header table is part of the memory image of the program. If it is present, it must precede any loadable segment entry. PT_LOPROC, PT_HIPROC Values in the inclusive range [PT_LOPROC, PT_HIPROC] are reserved for processor-specific semantics. PT_GNU_STACK GNU extension which is used by the Linux kernel to control the state of the stack via the flags set in the p_flags member. ","permalink":"https://R3x.github.io/posts/elf_1/","summary":"Digging into ELFs (Part 1) In this blog, I plan to look at the ELF file format, specifically the ELF headers, sections and segments. This is gonna be a part of a series that I hope to complete part-by-part this month.\nI am planning to use the LIEF python module to help me look at ELFs and understand what\u0026rsquo;s happening.\nOverview ELF file contains a header and data. The data is divided into segments, each segment can contian a number of sections.","title":"Digging into ELFs (Part 1)"},{"content":"Digging into ELFs (Part 2) Last time, I spent time looking at the ELF headers. And we got a decent idea of how the ELF file format stores data in various segments and sections. Now let\u0026rsquo;s look deeper into different sections that are present in the ELF file.\nWhat are those various sections? To view the sections using the LIEF python module, we can use the following script:\nimport lief binary = lief.parse(\u0026#34;a.out\u0026#34;) for section in binary.sections: print(section) Let\u0026rsquo;s look at some of the sections:\nSome of the more known ones are\n.text - This is the code section, where the opcodes for all the instructions are stored. This section is usually R and X (Read and Execute). .data - This is the global data section, where all the initialized global variables and static variables of functions are stored. This section is usually R and W (Read and Write). .rodata - This is the read only data section, where all the constants are stored (Like strings for examples). This section is usually R (Read). .bss - This is the uninitialized data section. Other sections present\n.comment section This section is used to store details about the ELF file. Such as information about the compiler etc. This section can be really useful while reverse engineering, to extract information about the compiler that was used to compile the ELF file.\nif binary.has_section(\u0026#34;.comment\u0026#34;): comment_sec = binary.get_section(\u0026#34;.comment\u0026#34;) print(comment_sec.content.to_bytes()) This gives the following output:\nb\u0026#39;GCC: (Ubuntu 11.2.0-19ubuntu1) 11.2.0\\x00\u0026#39; The above can be done using readelf as well:\nr3x@pop ~/r/elf\u0026gt; readelf -p .comment ./a.out String dump of section \u0026#39;.comment\u0026#39;: [ 0] GCC: (Ubuntu 11.2.0-19ubuntu1) 11.2.0 .interp section This section is used to store the name of the interpreter for the binary.\n","permalink":"https://R3x.github.io/posts/elf_2/","summary":"Digging into ELFs (Part 2) Last time, I spent time looking at the ELF headers. And we got a decent idea of how the ELF file format stores data in various segments and sections. Now let\u0026rsquo;s look deeper into different sections that are present in the ELF file.\nWhat are those various sections? To view the sections using the LIEF python module, we can use the following script:\nimport lief binary = lief.","title":"Digging into ELFs (Part 2)"},{"content":"Hello World! Yay! I finally decided to switch from wordpress to creating my own website. I was getting a lot of paywalls and it was becoming pretty painful to update the website every now and then.\nLet\u0026rsquo;s see how it goes.\n","permalink":"https://R3x.github.io/posts/temp/","summary":"Hello World! Yay! I finally decided to switch from wordpress to creating my own website. I was getting a lot of paywalls and it was becoming pretty painful to update the website every now and then.\nLet\u0026rsquo;s see how it goes.","title":"New Website/Blog"},{"content":"Exec System Call Welcome to the first installment in a blog series that will takes a deep dive into the mechanics of system calls. Today, we\u0026rsquo;re kicking things off with the exec system calls, a fundamental feature in Unix and Linux operating systems.\nGlibc version used : 2.37 Bootlin\nIntroduction to the exec library calls Note: Please skip this section if you are already familiar with exec library calls.\nIn Unix and Linux systems, the exec family of library calls plays an essential role in process creation and management. While the general role of each function in the exec family is similar, they differ in how they accept arguments and in certain behaviors. These are the functions a user would typically use to interface with the kernel (exec syscall) to create a new process.\nHere\u0026rsquo;s an introduction to each member of the exec family:\nexecve: This function is the core of all exec functions, which all others essentially wrap around. It allows the specification of the argument list and environment variables. It is the only exec function that is a system call that interfaces directly with the kernel.\nchar *args[] = {\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL}; char *env[] = {\u0026#34;PATH=/usr/bin\u0026#34;, NULL}; execve(\u0026#34;/bin/ls\u0026#34;, args, env); execl: This function takes a list of arguments individually, with the list terminated by a null pointer. It\u0026rsquo;s handy when the number of parameters is known in advance.\nexecl(\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL); execv: This function takes an array of pointers to null-terminated strings that represent the argument list available to the new program. It\u0026rsquo;s used when the number of parameters isn\u0026rsquo;t known beforehand.\nchar *args[] = {\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL}; execv(\u0026#34;/bin/ls\u0026#34;, args); execle: This function is similar to execl, but it also allows the caller to specify the environment of the executed program.\nchar *args[] = {\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL}; char *env[] = {\u0026#34;PATH=/usr/bin\u0026#34;, NULL}; execle(\u0026#34;/bin/ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL, env); execlp, execvp, execvpe and execlpe: These functions are similar to execl and execv, respectively. However, they use the PATH environment variable to find the program file to execute, which means you can use relative paths to executable files.\nchar *args[] = {\u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL}; char *env[] = {\u0026#34;PATH=/usr/bin\u0026#34;, NULL}; execlp(\u0026#34;ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL); // execvp(\u0026#34;ls\u0026#34;, args); // execvpe(\u0026#34;ls\u0026#34;, args, env); // execlpe(\u0026#34;ls\u0026#34;, \u0026#34;ls\u0026#34;, \u0026#34;-l\u0026#34;, NULL, env); // Library to the Kernel - Invoking The library calls can be found in the glibc source code, it\u0026rsquo;s not a surprice that they are just wrappers for calling the kernel functions. All functions were found in the posix directory.\nFor example, the execv function can be found in the execv.c file Link, and looks like this :\nint execv (const char *path, char *const argv[]) { return __execve (path, argv, __environ); } Let\u0026rsquo;s now look at how __execve in implemented, and how it calls the system-call. It can be found in execv.c Link\nint __execve (const char *path, char *const argv[], char *const envp[]) { if (path == NULL || argv == NULL || envp == NULL) { __set_errno (EINVAL); return -1; } __set_errno (ENOSYS); return -1; } stub_warning (execve) weak_alias (__execve, execve) Wait! So how does it actually call the system call? Okay looks like we are gonna have to dig into how the glibc calls the system call. Let\u0026rsquo;s look at both stub_warning and weak_alias functions.\nWhat is stub_warning? stub_warning is a macro that is defined in libc-symbols.h Link and looks like this (with comments added to explain):\n/* A canned warning for sysdeps/stub functions. */ #define\tstub_warning(name) \\ __make_section_unallocated (\u0026#34;.gnu.glibc-stub.\u0026#34; #name) \\ link_warning (name, #name \u0026#34; is not implemented and will always fail\u0026#34;) #define __make_section_unallocated(section_string)\t\\ asm (\u0026#34;.section \u0026#34; section_string \u0026#34;\\n\\t.previous\u0026#34;); #define link_warning(symbol, msg) \\ __make_section_unallocated (\u0026#34;.gnu.warning.\u0026#34; #symbol) \\ static const char __evoke_link_warning_##symbol[]\t\\ __attribute__ ((used, section (\u0026#34;.gnu.warning.\u0026#34; #symbol __sec_comment))) \\ = msg; For some context :\n.section - This is a assembler directive to the assembler to switch to a different section. The section name is passed as an argument to the directive. .previous - This is a assembler directive to the assembler to switch back to the previous section. So the __make_section_unallocated switches to a different section, and then has the .previous directive to switch back to the previous section. This is done to make sure that the section is not allocated in the final binary.\nlink_warning(symbol, msg): This macro defines a string with a warning message (msg) that will be associated with the symbol. The string is placed in a special section (.gnu.warning.symbol) of the binary.\nThe idea here is that when the function (stub) is used, the linker will see the .gnu.warning.symbol section and output the warning message. This allows for a message to be shown at link time if a stub function is being used.\n\u0026hellip;. TODO: rest\n","permalink":"https://R3x.github.io/posts/linux_system_calls/exec/","summary":"Exec System Call Welcome to the first installment in a blog series that will takes a deep dive into the mechanics of system calls. Today, we\u0026rsquo;re kicking things off with the exec system calls, a fundamental feature in Unix and Linux operating systems.\nGlibc version used : 2.37 Bootlin\nIntroduction to the exec library calls Note: Please skip this section if you are already familiar with exec library calls.\nIn Unix and Linux systems, the exec family of library calls plays an essential role in process creation and management.","title":"Exec System Call"}]